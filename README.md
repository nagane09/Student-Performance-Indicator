# Student Performance Indicator

ðŸ”— **Live Demo:** https://student-performance-indicator-3.onrender.com/

---

---

# **Predicting Student Performance Using Machine Learning**  

This project implements an **end-to-end machine learning pipeline** for predicting studentsâ€™ final math scores based on demographic, socio-economic, and academic features. Beyond building predictive models, the project includes **statistical exploration, hypothesis testing, and feature importance analysis**, making it **research-oriented** and aligned with graduate-level data science standards.

---

## **1. Abstract**

Early prediction of student performance enables targeted interventions for at-risk students. This project leverages **machine learning and statistical analysis** to predict final math scores using:

- Demographics (gender, race/ethnicity, parental education)  
- Socio-economic features (lunch type, test preparation)  
- Academic performance (reading and writing scores)  

**Key contributions:**

- End-to-end ML pipeline with preprocessing, training, evaluation, and deployment  
- Comparative evaluation of 7 regression models  
- Statistical and exploratory data analysis (EDA) to understand relationships and validate assumptions  
- Hypothesis testing (t-tests, ANOVA) to uncover significant factors  
- Feature importance analysis and visualization  
- Deployment via a Flask web interface for real-time predictions  

**Best model:** Linear Regression with **87.9% accuracy** on test data.

---

## **2. Problem Statement**

Given student features:

X = { gender, race_ethnicity, parental_education, lunch, test_preparation, reading_score, writing_score }


Predict final math score:
y_pred = f(X; Î¸)


where `f` is a regression model and Î¸ represents learned parameters.

---

## **3. Dataset**

- **Source:** Public student performance dataset (~1000 records)  
- **Features:**

| Feature | Description |
|---------|-------------|
| gender | Male/Female |
| race_ethnicity | Group Aâ€“E |
| parental_level_of_education | Highest parental education |
| lunch | Standard / Free |
| test_preparation_course | Completed / None |
| reading_score | Reading exam score |
| writing_score | Writing exam score |
| math_score | Target variable |

- **Train/Test Split:** 80% / 20%  
- **Missing Values:** Imputed (median for numerical, most frequent for categorical)

---

## 4. Exploratory Data Analysis (EDA) & Statistical Analysis

### 4.1 Correlation Analysis

|            | reading_score | writing_score | math_score |
|------------|---------------|---------------|------------|
| reading_score | 1.000         | 0.956         | 0.815      |
| writing_score | 0.956         | 1.000         | 0.802      |
| math_score    | 0.815         | 0.802         | 1.000      |

**Observation:** Reading and writing scores are strongly correlated with final math score.

---

### 4.2 Distribution & Outliers

- Histograms and boxplots were used to check skewness and outliers.
- Reading and writing scores are roughly normally distributed.
- Minor outliers exist but do not significantly affect model training.

---

### 4.3 Hypothesis Testing

**T-test: Lunch Type**

```python
group_standard = data[data["lunch"]=="standard"]["math_score"]
group_free = data[data["lunch"]=="free"]["math_score"]
t_stat, p_val = ttest_ind(group_standard, group_free)
```
Result: T-test indicates difference in math scores based on lunch type.

### ANOVA: Race/Ethnicity

```bash
groups = [data[data["race_ethnicity"]==g]["math_score"] for g in data["race_ethnicity"].unique()]
f_stat, p_val = f_oneway(*groups)
```

Result: Statistically significant differences exist across racial/ethnic groups (p << 0.05).

## 5. Data Preprocessing

- **Numerical Features:** Median imputation + StandardScaler  
- **Categorical Features:** Most frequent imputation + OneHotEncoder + StandardScaler (with_mean=False)  
- **Pipeline:** ColumnTransformer saved as `preprocessor.pkl`  
- Transformed training and test arrays stored for reproducibility

---

## 6. Model Training

**Models Tested:**

- Linear Regression âœ… (selected)  
- Decision Tree Regressor  
- Random Forest Regressor  
- Gradient Boosting Regressor  
- XGB Regressor  
- CatBoost Regressor  
- AdaBoost Regressor  

**Performance:**  
- Linear Regression achieved **RÂ² = 0.879** and is interpretable for research purposes.  
- Pipeline saved as `model.pkl`

---

## 7. Feature Importance & Insights

- Linear regression coefficients indicate **reading_score** has slightly higher predictive power than **writing_score**.  
- Socio-economic features (**lunch**, **test preparation**) show weaker but measurable effects.  
- Statistical analysis confirms that differences across groups are significant, providing actionable insights.

---

## 8. Deployment

- **Framework:** Flask  
- **Functionality:**  
  - Users input student features via web form  
  - Data transformed using `preprocessor.pkl`  
  - Predictions generated by `model.pkl`  
  - Results displayed in real time  

**Inference Workflow:**

```python
preprocessor = load_object("artifacts/preprocessor.pkl")
model = load_object("artifacts/model.pkl")
network_model = PredictPipeline(preprocessor, model)
predictions = network_model.predict(input_df)
```

## 9. Evaluation Metrics

| Metric | Value |
|--------|-------|
| Mean Squared Error (MSE) | 38.12 |
| Mean Absolute Error (MAE) | 4.28 |
| RÂ² Score | 0.879 |
| Accuracy (rounded) | 87.9% |

---

## 10. Limitations & Future Work

- Extend features to include **attendance, participation, homework scores**  
- Explore **stacking/ensemble methods** for improved performance  
- Apply **SHAP/LIME** for interpretability  
- Integrate **temporal analysis** if multiple exams available  
- Investigate **fairness and bias** across socio-economic and racial groups
